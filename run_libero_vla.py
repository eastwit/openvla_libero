import os
import sys
import torch
import numpy as np
from PIL import Image
import glob
from transformers import AutoModelForVision2Seq, AutoProcessor, BitsAndBytesConfig

# ==========================================
# 1. ç¯å¢ƒä¿®å¤ä¸è·¯å¾„åˆå§‹åŒ–
# ==========================================
# è§£å†³æ¸²æŸ“å™¨ GLEW åŠ è½½é—®é¢˜ï¼ˆUbuntu å¸¸è§é—®é¢˜ï¼‰
glew_paths = glob.glob("/usr/lib/x86_64-linux-gnu/libGLEW.so*")
if glew_paths: 
    os.environ["LD_PRELOAD"] = glew_paths[-1]

# ä½¿ç”¨é•œåƒåŠ é€Ÿä¸‹è½½
os.environ["HF_ENDPOINT"] = "https://hf-mirror.com"

print("--- æ­£åœ¨åˆå§‹åŒ– LIBERO ç¯å¢ƒ ---")
try:
    from libero.libero import benchmark
    from libero.libero.envs import OffScreenRenderEnv
    print("âœ… LIBERO å¯¼å…¥æˆåŠŸï¼")
except Exception as e:
    print(f"âŒ å¯¼å…¥å¤±è´¥: {e}"); sys.exit()

# ==========================================
# 2. OpenVLA æ¨¡å‹åŠ è½½ (æè‡´æ˜¾å­˜ä¼˜åŒ–)
# ==========================================
model_id = "openvla/openvla-7b"
print(f"--- æ­£åœ¨åŠ è½½ OpenVLA æ¨¡å‹ (4-bit æ¨¡å¼) ---")

# é…ç½® 4-bit é‡åŒ–ä»¥é€‚åº” 8GB æ˜¾å­˜
q_config = BitsAndBytesConfig(
    load_in_4bit=True,
    bnb_4bit_compute_dtype=torch.bfloat16, # 4060 æ”¯æŒ bf16ï¼Œé€Ÿåº¦æ›´å¿«
    bnb_4bit_quant_type="nf4",
    bnb_4bit_use_double_quant=True,
)

processor = AutoProcessor.from_pretrained(model_id, trust_remote_code=True)

# ä¿®å¤æ ¸å¿ƒï¼šæ˜¾å¼æŒ‡å®š device_map é¿å… transformers å†…éƒ¨ .to() æŠ¥é”™
vla = AutoModelForVision2Seq.from_pretrained(
    model_id, 
    quantization_config=q_config,
    low_cpu_mem_usage=True, 
    trust_remote_code=True,
    device_map="cuda:0" 
)

# æ˜¾å­˜ä¼˜åŒ–ï¼šç¦ç”¨æ¨ç†ç¼“å­˜
vla.config.use_cache = False 
print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼å½“å‰æ˜¾å­˜å ç”¨: {torch.cuda.memory_allocated()/1024**3:.2f} GB")

# ==========================================
# 3. LIBERO ä»¿çœŸç¯å¢ƒå¯åŠ¨ (API é€‚é…ç‰ˆ)
# ==========================================
benchmark_dict = benchmark.get_benchmark_dict()
task_suite = benchmark_dict["libero_spatial"]() 
task_id = 0 

# æ ¹æ®ä½ çš„è°ƒè¯•ä¿¡æ¯ï¼ŒTask æ˜¯ä¸ª NamedTupleï¼ŒåŒ…å« bddl_file ç­‰è·¯å¾„
task = task_suite.get_task(task_id)
task_description = task.language 
print(f"--- ä»»åŠ¡æŒ‡ä»¤: {task_description} ---")

# æ„é€ ç¯å¢ƒå‚æ•° (é€‚é…ä½ çš„ Task å¯¹è±¡å±æ€§)
env_args = {
    "bddl_file_name": task.bddl_file,
    "camera_height": 224, # OpenVLA æ ‡å‡†è¾“å…¥åˆ†è¾¨ç‡
    "camera_width": 224,
    "device_id": 0       # æ˜ç¡®æŒ‡å®šæ¸²æŸ“ç”¨çš„æ˜¾å¡ ID
}

# å¦‚æœä½ çš„ LIBERO ç‰ˆæœ¬æ”¯æŒä»åˆå§‹çŠ¶æ€æ–‡ä»¶åŠ è½½
if hasattr(task, 'init_states_file'):
    env_args["initial_state_path"] = task.init_states_file

print("--- æ­£åœ¨åˆ›å»ºä»¿çœŸç¯å¢ƒ ---")
env = OffScreenRenderEnv(**env_args)
obs = env.reset()

# ==========================================
# 4. é—­ç¯æ§åˆ¶æ¨ç†å¾ªç¯
# ==========================================
print("--- æœºå™¨äººæ§åˆ¶æ­£å¼å¼€å§‹ ---")
try:
    for step in range(200):
        # å›¾åƒå¤„ç†ï¼šLIBERO çš„ agentview å›¾åƒé€šå¸¸éœ€è¦å‚ç›´ç¿»è½¬
        img_np = obs["agentview_image"]
        img_np = np.flipud(img_np) 
        img = Image.fromarray(img_np)
        
        # å‡†å¤‡æ¨¡å‹è¾“å…¥
        inputs = processor(task_description, img, return_tensors="pt").to("cuda:0", dtype=torch.bfloat16)
        
        with torch.inference_mode():
            # OpenVLA æ¨ç†åŠ¨ä½œ (7ç»´å‘é‡: [x, y, z, roll, pitch, yaw, gripper])
            action = vla.predict_action(**inputs, unnorm_key="bridge_orig")
        
        # åŠ¨ä½œæ‰§è¡Œ
        if hasattr(action, 'cpu'):
            action = action.cpu().numpy()
            
        obs, reward, done, info = env.step(action)
        
        # æ¯ 10 æ­¥æ‰“å°ä¸€æ¬¡çŠ¶æ€å¹¶ä¿å­˜å›¾ç‰‡
        if step % 10 == 0:
            vram = torch.cuda.memory_allocated()/1024**3
            print(f"Step {step}: AI æ­£åœ¨æ“æ§... æ˜¾å­˜: {vram:.2f} GB")
            img.save(f"step_{step}.png")
            # å®šæœŸæ¸…ç†æ˜¾å­˜ç¢ç‰‡é˜²æ­¢ 8GB æº¢å‡º
            torch.cuda.empty_cache()
            
        if done or reward > 0: 
            print("ğŸ‰ ä»»åŠ¡ç›®æ ‡è¾¾æˆæˆ–ç¯å¢ƒç»ˆæ­¢ï¼")
            break
            
except Exception as e:
    print(f"âŒ è¿è¡Œä¸­å‡ºé”™: {e}")
finally:
    if 'env' in locals(): 
        env.close()
    print("--- ä»¿çœŸç»“æŸå¹¶å®‰å…¨é€€å‡º ---")