import os
import sys
import torch
import numpy as np
from PIL import Image
import glob
from transformers import AutoModelForVision2Seq, AutoProcessor, BitsAndBytesConfig

# ==========================================
# 1. ç¯å¢ƒä¿®å¤ä¸è·¯å¾„åˆå§‹åŒ–
# ==========================================
# è§£å†³æ¸²æŸ“å™¨ GLEW åŠ è½½é—®é¢˜
glew_paths = glob.glob("/usr/lib/x86_64-linux-gnu/libGLEW.so*")
if glew_paths: 
    os.environ["LD_PRELOAD"] = glew_paths[-1]

# ä½¿ç”¨é•œåƒåŠ é€Ÿä¸‹è½½
os.environ["HF_ENDPOINT"] = "https://hf-mirror.com"

print("--- æ­£åœ¨åˆå§‹åŒ– LIBERO ç¯å¢ƒ ---")
try:
    from libero.libero import benchmark
    from libero.libero.envs import OffScreenRenderEnv
    from libero.libero.utils.file_utils import get_bddl_path
    print("âœ… LIBERO å¯¼å…¥æˆåŠŸï¼")
except Exception as e:
    print(f"âŒ å¯¼å…¥å¤±è´¥: {e}"); sys.exit()

# ==========================================
# 2. OpenVLA æ¨¡å‹åŠ è½½ (4-bit æè‡´ä¼˜åŒ–)
# ==========================================
model_id = "openvla/openvla-7b"
print(f"--- æ­£åœ¨åŠ è½½ OpenVLA æ¨¡å‹ (4-bit æ¨¡å¼) ---")

q_config = BitsAndBytesConfig(
    load_in_4bit=True,
    bnb_4bit_compute_dtype=torch.bfloat16, 
    bnb_4bit_quant_type="nf4",
    bnb_4bit_use_double_quant=True,
)

processor = AutoProcessor.from_pretrained(model_id, trust_remote_code=True)
vla = AutoModelForVision2Seq.from_pretrained(
    model_id, 
    quantization_config=q_config,
    low_cpu_mem_usage=True, 
    trust_remote_code=True,
    device_map="cuda:0" 
)

# æ˜¾å­˜ä¼˜åŒ–
vla.config.use_cache = False 
print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼å½“å‰æ˜¾å­˜å ç”¨: {torch.cuda.memory_allocated()/1024**3:.2f} GB")

# ==========================================
# 3. LIBERO ä»¿çœŸç¯å¢ƒå¯åŠ¨ (ä¿®å¤ BDDL è·¯å¾„)
# ==========================================
benchmark_dict = benchmark.get_benchmark_dict()
task_suite = benchmark_dict["libero_spatial"]() 
task_id = 0 

task = task_suite.get_task(task_id)
task_description = task.language 
print(f"--- ä»»åŠ¡æŒ‡ä»¤: {task_description} ---")

# å…³é”®ä¿®å¤ï¼šè·å– BDDL æ–‡ä»¶çš„ç»å¯¹è·¯å¾„
actual_bddl_path = get_bddl_path(task.bddl_file)
print(f"ğŸ“ æ­£åœ¨å®šä½ BDDL: {actual_bddl_path}")

env_args = {
    "bddl_file_name": actual_bddl_path,
    "camera_height": 224,
    "camera_width": 224,
    "device_id": 0
}

print("--- æ­£åœ¨åˆ›å»ºä»¿çœŸç¯å¢ƒ ---")
env = OffScreenRenderEnv(**env_args)
obs = env.reset()

# ==========================================
# 4. é—­ç¯æ§åˆ¶æ¨ç†å¾ªç¯
# ==========================================
print("--- æœºå™¨äººæ§åˆ¶æ­£å¼å¼€å§‹ ---")
try:
    for step in range(200):
        # 1. å›¾åƒé¢„å¤„ç†ï¼šç¿»è½¬ + RGB è½¬æ¢
        img_np = obs["agentview_image"]
        img_np = np.flipud(img_np) 
        img = Image.fromarray(img_np).convert("RGB")
        
        # 2. å‡†å¤‡æ¨¡å‹è¾“å…¥
        inputs = processor(task_description, img, return_tensors="pt").to("cuda:0", dtype=torch.bfloat16)
        
        # 3. OpenVLA æ¨ç†åŠ¨ä½œ
        with torch.inference_mode():
            # æ˜¾å¼æŒ‡å®šè¾“å…¥å­—æ®µï¼Œç¡®ä¿ç¨³å®šæ€§
            action = vla.predict_action(
                input_ids=inputs["input_ids"],
                pixel_values=inputs["pixel_values"],
                unnorm_key="bridge_orig"
            )
        
        # 4. åŠ¨ä½œåå¤„ç†
        if hasattr(action, 'cpu'):
            action = action.cpu().numpy()
        
        # é™åˆ¶åŠ¨ä½œèŒƒå›´ï¼Œé˜²æ­¢ä»¿çœŸå™¨å› å¼‚å¸¸æ•°å€¼å´©æºƒ
        action = np.clip(action, -1.0, 1.0)
            
        # 5. æ‰§è¡Œæ­¥è¿›
        obs, reward, done, info = env.step(action)
        
        # 6. çŠ¶æ€åé¦ˆä¸æ—¥å¿—
        if step % 5 == 0:
            vram = torch.cuda.memory_allocated()/1024**3
            print(f"Step {step}: æ­£åœ¨æ‰§è¡Œ... æ˜¾å­˜: {vram:.2f} GB | Reward: {reward}")
            img.save(f"step_{step}.png")
            # é‡Šæ”¾ç¼“å­˜é˜²æ­¢ç¢ç‰‡åŒ– OOM
            torch.cuda.empty_cache()
            
        if done or reward > 0: 
            print("ğŸ‰ ä»»åŠ¡æˆåŠŸè¾¾æˆï¼")
            break
            
except Exception as e:
    print(f"âŒ è¿è¡Œä¸­å‡ºé”™: {e}")
    import traceback
    traceback.print_exc()
finally:
    if 'env' in locals(): 
        env.close()
    print("--- ä»¿çœŸç»“æŸå¹¶å®‰å…¨é€€å‡º ---")